{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGW9lkAKfKCd"
      },
      "source": [
        "# Лабораторная работа 4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гуськова Кристина Игоревна, 6409-010302D"
      ],
      "metadata": {
        "id": "2uMRsPPogeyf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il7z5Bs_fKCi"
      },
      "source": [
        "Tensorflow 2.x\n",
        "\n",
        "1) Подготовка данных\n",
        "\n",
        "2) Использование Keras Model API\n",
        "\n",
        "3) Использование Keras Sequential + Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GgI2Vw_fKCj"
      },
      "source": [
        "https://www.tensorflow.org/tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNmr5jsYfKCk"
      },
      "source": [
        "Для выполнения лабораторной работы необходимо установить tensorflow версии 2.0 или выше .\n",
        "\n",
        "Рекомендуется использовать возможности Colab'а по обучению моделей на GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qmGFp5apfKCk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgsVRO-5fKCm"
      },
      "source": [
        "# Подготовка данных\n",
        "Загрузите набор данных из предыдущей лабораторной работы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR6sxfFFfKCn",
        "outputId": "dceda1bf-774e-42b4-a783-fc4f4a16876d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Train data shape:  (49000, 32, 32, 3)\n",
            "Train labels shape:  (49000,) int32\n",
            "Validation data shape:  (1000, 32, 32, 3)\n",
            "Validation labels shape:  (1000,)\n",
            "Test data shape:  (10000, 32, 32, 3)\n",
            "Test labels shape:  (10000,)\n"
          ]
        }
      ],
      "source": [
        "def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n",
        "    \"\"\"\n",
        "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
        "    it for the two-layer neural net classifier. These are the same steps as\n",
        "    we used for the SVM, but condensed to a single function.\n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
        "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10\n",
        "    X_train = np.asarray(X_train, dtype=np.float32)\n",
        "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
        "    X_test = np.asarray(X_test, dtype=np.float32)\n",
        "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
        "\n",
        "    # Subsample the data\n",
        "    mask = range(num_training, num_training + num_validation)\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = range(num_training)\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = range(num_test)\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    # Normalize the data: subtract the mean pixel and divide by std\n",
        "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
        "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
        "    X_train = (X_train - mean_pixel) / std_pixel\n",
        "    X_val = (X_val - mean_pixel) / std_pixel\n",
        "    X_test = (X_test - mean_pixel) / std_pixel\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "# If there are errors with SSL downloading involving self-signed certificates,\n",
        "# it may be that your Python version was recently installed on the current machine.\n",
        "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
        "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
        "#   ...replacing paths as necessary.\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "NHW = (0, 1, 2)\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eNdVz56hfKCp"
      },
      "outputs": [],
      "source": [
        "class Dataset(object):\n",
        "    def __init__(self, X, y, batch_size, shuffle=False):\n",
        "        \"\"\"\n",
        "        Construct a Dataset object to iterate over data X and labels y\n",
        "\n",
        "        Inputs:\n",
        "        - X: Numpy array of data, of any shape\n",
        "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
        "        - batch_size: Integer giving number of elements per minibatch\n",
        "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
        "        \"\"\"\n",
        "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
        "        self.X, self.y = X, y\n",
        "        self.batch_size, self.shuffle = batch_size, shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        N, B = self.X.shape[0], self.batch_size\n",
        "        idxs = np.arange(N)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(idxs)\n",
        "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
        "\n",
        "\n",
        "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
        "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
        "test_dset = Dataset(X_test, y_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tkz4qz1fKCq",
        "outputId": "7def3d5e-8dad-4a6b-8337-801d1d09ad9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (64, 32, 32, 3) (64,)\n",
            "1 (64, 32, 32, 3) (64,)\n",
            "2 (64, 32, 32, 3) (64,)\n",
            "3 (64, 32, 32, 3) (64,)\n",
            "4 (64, 32, 32, 3) (64,)\n",
            "5 (64, 32, 32, 3) (64,)\n",
            "6 (64, 32, 32, 3) (64,)\n"
          ]
        }
      ],
      "source": [
        "# We can iterate through a dataset like this:\n",
        "for t, (x, y) in enumerate(train_dset):\n",
        "    print(t, x.shape, y.shape)\n",
        "    if t > 5: break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3mSSyFMfKCr"
      },
      "source": [
        "#  Keras Model Subclassing API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U32ojubmfKCr"
      },
      "source": [
        "\n",
        "Для реализации собственной модели с помощью Keras Model Subclassing API необходимо выполнить следующие шаги:\n",
        "\n",
        "1) Определить новый класс, который является наследником tf.keras.Model.\n",
        "\n",
        "2) В методе __init__() определить все необходимые слои из модуля tf.keras.layer\n",
        "\n",
        "3) Реализовать прямой проход в методе call() на основе слоев, объявленных в __init__()\n",
        "\n",
        "Ниже приведен пример использования keras API для определения двухслойной полносвязной сети.\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS3A6tCgfKCs",
        "outputId": "ca8d759b-027f-47f8-e1e8-11dca19aa8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "USE_GPU = True # устанавливаем флаг для использования GPU\n",
        "\n",
        "# проверяем наличие GPU и выбираем устройство\n",
        "if USE_GPU:\n",
        "    device = '/device:GPU:0'\n",
        "else:\n",
        "    device = '/cpu:0'\n",
        "\n",
        "print('Using device: ', device) # выводим выбранное устройство\n",
        "\n",
        "print_every = 100 # определяем константу для контроля частоты вывода информации во время обучения моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSVEwDszfKCt",
        "outputId": "743a0a30-1a1f-4490-e22c-1665736ec5ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "class TwoLayerFC(tf.keras.Model):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(TwoLayerFC, self).__init__()\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
        "                                   kernel_initializer=initializer)\n",
        "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                                   kernel_initializer=initializer)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def test_TwoLayerFC():\n",
        "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
        "    input_size, hidden_size, num_classes = 50, 42, 10\n",
        "    x = tf.zeros((64, input_size))\n",
        "    model = TwoLayerFC(hidden_size, num_classes)\n",
        "    with tf.device(device):\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "\n",
        "test_TwoLayerFC()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUrqFTJIfKCu"
      },
      "source": [
        "Реализуйте трехслойную CNN для вашей задачи классификации.\n",
        "\n",
        "Архитектура сети:\n",
        "    \n",
        "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
        "2. Функция активации ReLU\n",
        "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
        "4. Функция активации ReLU\n",
        "5. Полносвязный слой\n",
        "6. Функция активации Softmax\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SGVQEDRifKCu"
      },
      "outputs": [],
      "source": [
        "class ThreeLayerConvNet(tf.keras.Model):\n",
        "    def __init__(self, channel_1, channel_2, num_classes):\n",
        "        super(ThreeLayerConvNet, self).__init__()\n",
        "        ########################################################################\n",
        "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
        "        # should instantiate layer objects to be used in the forward pass.     #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0) # определяем инициализатор весов\n",
        "\n",
        "        self.flatten = tf.keras.layers.Flatten() # создаем слой Flatten, который преобразует входные данные в одномерный массив\n",
        "\n",
        "        # создаем сверточные слои conv1 и conv2\n",
        "        self.conv1 = tf.keras.layers.Conv2D(channel_1, [5, 5], [1, 1], padding='same',\n",
        "                                            kernel_initializer=initializer,\n",
        "                                            activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(channel_2, [3, 3], [1, 1], padding='same',\n",
        "                                            kernel_initializer=initializer,\n",
        "                                            activation='relu')\n",
        "\n",
        "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=initializer) # создаем полносвязный слой fc с указанным количеством классов и функцией активации softmax\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                           END OF YOUR CODE                           #\n",
        "        ########################################################################\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        scores = None\n",
        "        ########################################################################\n",
        "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
        "        # should use the layer objects defined in the __init__ method.         #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        x = self.conv1(x) # пропускаем входные данные через первый сверточный слой conv1\n",
        "\n",
        "        x = self.conv2(x) # пропускаем полученные данные через второй сверточный слой conv2\n",
        "\n",
        "        x = self.flatten(x) # преобразовываем данные в плоский формат с помощью слоя Flatten\n",
        "\n",
        "        scores = self.fc(x) # вычисляем значения оценок классов с помощью полносвязного слоя fc\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                           END OF YOUR CODE                           #\n",
        "        ########################################################################\n",
        "        return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UtscGyHfKCv",
        "outputId": "6d91584c-7be6-4a22-c1c8-4605c356eb0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ],
      "source": [
        "def test_ThreeLayerConvNet():\n",
        "    channel_1, channel_2, num_classes = 12, 8, 10\n",
        "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
        "    with tf.device(device):\n",
        "        x = tf.zeros((64, 3, 32, 32))\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "\n",
        "test_ThreeLayerConvNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbIxfeuCfKCw"
      },
      "source": [
        "Пример реализации процесса обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T6qXIGZmfKCw"
      },
      "outputs": [],
      "source": [
        "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n",
        "    \"\"\"\n",
        "    Simple training loop for use with models defined using tf.keras. It trains\n",
        "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
        "    accuracy on the CIFAR-10 validation set.\n",
        "\n",
        "    Inputs:\n",
        "    - model_init_fn: A function that takes no parameters; when called it\n",
        "      constructs the model we want to train: model = model_init_fn()\n",
        "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
        "      constructs the Optimizer object we will use to optimize the model:\n",
        "      optimizer = optimizer_init_fn()\n",
        "    - num_epochs: The number of epochs to train for\n",
        "\n",
        "    Returns: Nothing, but prints progress during trainingn\n",
        "    \"\"\"\n",
        "    with tf.device(device):\n",
        "\n",
        "\n",
        "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "        model = model_init_fn()\n",
        "        optimizer = optimizer_init_fn()\n",
        "\n",
        "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
        "\n",
        "        t = 0\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
        "            train_loss.reset_states()\n",
        "            train_accuracy.reset_states()\n",
        "\n",
        "            for x_np, y_np in train_dset:\n",
        "                with tf.GradientTape() as tape:\n",
        "\n",
        "                    # Use the model function to build the forward pass.\n",
        "                    scores = model(x_np, training=is_training)\n",
        "                    loss = loss_fn(y_np, scores)\n",
        "\n",
        "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "                    # Update the metrics\n",
        "                    train_loss.update_state(loss)\n",
        "                    train_accuracy.update_state(y_np, scores)\n",
        "\n",
        "                    if t % print_every == 0:\n",
        "                        val_loss.reset_states()\n",
        "                        val_accuracy.reset_states()\n",
        "                        for test_x, test_y in val_dset:\n",
        "                            # During validation at end of epoch, training set to False\n",
        "                            prediction = model(test_x, training=False)\n",
        "                            t_loss = loss_fn(test_y, prediction)\n",
        "\n",
        "                            val_loss.update_state(t_loss)\n",
        "                            val_accuracy.update_state(test_y, prediction)\n",
        "\n",
        "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
        "                        print (template.format(t, epoch+1,\n",
        "                                             train_loss.result(),\n",
        "                                             train_accuracy.result()*100,\n",
        "                                             val_loss.result(),\n",
        "                                             val_accuracy.result()*100))\n",
        "                    t += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F92NAf-nfKCx",
        "outputId": "b3140498-dc7a-42c2-e392-675fe8ccfa40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.9944493770599365, Accuracy: 4.6875, Val Loss: 2.924266815185547, Val Accuracy: 12.5\n",
            "Iteration 100, Epoch 1, Loss: 2.2359302043914795, Accuracy: 28.589109420776367, Val Loss: 1.8716316223144531, Val Accuracy: 38.60000228881836\n",
            "Iteration 200, Epoch 1, Loss: 2.0715084075927734, Accuracy: 32.26834487915039, Val Loss: 1.8199480772018433, Val Accuracy: 39.5\n",
            "Iteration 300, Epoch 1, Loss: 2.002737045288086, Accuracy: 33.79360580444336, Val Loss: 1.8823935985565186, Val Accuracy: 36.5\n",
            "Iteration 400, Epoch 1, Loss: 1.936016321182251, Accuracy: 35.617984771728516, Val Loss: 1.7014447450637817, Val Accuracy: 43.5\n",
            "Iteration 500, Epoch 1, Loss: 1.8919559717178345, Accuracy: 36.79827880859375, Val Loss: 1.636350393295288, Val Accuracy: 43.5\n",
            "Iteration 600, Epoch 1, Loss: 1.8604825735092163, Accuracy: 37.68718719482422, Val Loss: 1.645999550819397, Val Accuracy: 44.60000228881836\n",
            "Iteration 700, Epoch 1, Loss: 1.8346121311187744, Accuracy: 38.40495681762695, Val Loss: 1.620166540145874, Val Accuracy: 45.10000228881836\n"
          ]
        }
      ],
      "source": [
        "hidden_size, num_classes = 4000, 10\n",
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    return TwoLayerFC(hidden_size, num_classes)\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbyIytDdfKCy"
      },
      "source": [
        "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9 .\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n",
        "\n",
        "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50% ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WtumcNnfKCy",
        "outputId": "3ff671ee-7102-46f6-8fd4-db2566908933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.163867950439453, Accuracy: 3.125, Val Loss: 7.5835490226745605, Val Accuracy: 11.0\n",
            "Iteration 100, Epoch 1, Loss: 2.2278711795806885, Accuracy: 25.696165084838867, Val Loss: 1.833018183708191, Val Accuracy: 35.5\n",
            "Iteration 200, Epoch 1, Loss: 1.997072696685791, Accuracy: 31.786378860473633, Val Loss: 1.656759262084961, Val Accuracy: 42.29999923706055\n",
            "Iteration 300, Epoch 1, Loss: 1.8762261867523193, Accuracy: 35.21075439453125, Val Loss: 1.5778638124465942, Val Accuracy: 45.400001525878906\n",
            "Iteration 400, Epoch 1, Loss: 1.7847610712051392, Accuracy: 38.084476470947266, Val Loss: 1.4887930154800415, Val Accuracy: 47.900001525878906\n",
            "Iteration 500, Epoch 1, Loss: 1.7244035005569458, Accuracy: 39.77046203613281, Val Loss: 1.4418889284133911, Val Accuracy: 48.89999771118164\n",
            "Iteration 600, Epoch 1, Loss: 1.6797679662704468, Accuracy: 41.061771392822266, Val Loss: 1.4115409851074219, Val Accuracy: 49.599998474121094\n",
            "Iteration 700, Epoch 1, Loss: 1.6424200534820557, Accuracy: 42.22316360473633, Val Loss: 1.3870826959609985, Val Accuracy: 52.0\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 3e-3\n",
        "channel_1, channel_2, num_classes = 32, 16, 10\n",
        "\n",
        "def model_init_fn():\n",
        "    model = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes) # создаем модель трехслойной сверточной нейронной сети ThreeLayerConvNet\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return model\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    optimizer = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate, 0.9, nesterov=True) # создаем оптимизатор стохастического градиентного спуска SGD с моментом и использованием Nesterov momentum\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return optimizer\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUN-r1VXfKCz"
      },
      "source": [
        "# Использование Keras Sequential API для реализации последовательных моделей.\n",
        "\n",
        "Пример для полносвязной сети:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEdrwKjIfKC0",
        "outputId": "e1462731-9784-44bb-f409-621d2bd33416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.6791768074035645, Accuracy: 15.625, Val Loss: 2.974302053451538, Val Accuracy: 13.600000381469727\n",
            "Iteration 100, Epoch 1, Loss: 2.2370293140411377, Accuracy: 28.86757469177246, Val Loss: 1.9311957359313965, Val Accuracy: 37.70000076293945\n",
            "Iteration 200, Epoch 1, Loss: 2.0839684009552, Accuracy: 32.20615768432617, Val Loss: 1.8250834941864014, Val Accuracy: 39.099998474121094\n",
            "Iteration 300, Epoch 1, Loss: 2.004880666732788, Accuracy: 34.14140319824219, Val Loss: 1.8983943462371826, Val Accuracy: 36.89999771118164\n",
            "Iteration 400, Epoch 1, Loss: 1.934259295463562, Accuracy: 35.86736297607422, Val Loss: 1.7530382871627808, Val Accuracy: 41.10000228881836\n",
            "Iteration 500, Epoch 1, Loss: 1.889353632926941, Accuracy: 36.94797897338867, Val Loss: 1.6591806411743164, Val Accuracy: 42.5\n",
            "Iteration 600, Epoch 1, Loss: 1.85896897315979, Accuracy: 37.863975524902344, Val Loss: 1.686116337776184, Val Accuracy: 42.20000076293945\n",
            "Iteration 700, Epoch 1, Loss: 1.8337247371673584, Accuracy: 38.534236907958984, Val Loss: 1.6519715785980225, Val Accuracy: 44.60000228881836\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    input_shape = (32, 32, 3)\n",
        "    hidden_layer_size, num_classes = 4000, 10\n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "    layers = [\n",
        "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
        "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
        "                              kernel_initializer=initializer),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                              kernel_initializer=initializer),\n",
        "    ]\n",
        "    model = tf.keras.Sequential(layers)\n",
        "    return model\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZDGwgQMfKC0"
      },
      "source": [
        "Альтернативный менее гибкий способ обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAIeMzj6fKC1",
        "outputId": "39f21002-8207-4349-d4f4-79a730dfc91e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "766/766 [==============================] - 101s 131ms/step - loss: 1.8251 - sparse_categorical_accuracy: 0.3847 - val_loss: 1.7583 - val_sparse_categorical_accuracy: 0.4080\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 1.7622 - sparse_categorical_accuracy: 0.4013\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7621982097625732, 0.40130001306533813]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model = model_init_fn()\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Olq_0RHfKC1"
      },
      "source": [
        "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wj9zfHIfKC2",
        "outputId": "febbf425-665a-48f7-d0f8-40ddb3060491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.0395925045013428, Accuracy: 4.6875, Val Loss: 2.8093976974487305, Val Accuracy: 8.0\n",
            "Iteration 100, Epoch 1, Loss: 2.087306499481201, Accuracy: 26.48514747619629, Val Loss: 1.839172124862671, Val Accuracy: 35.400001525878906\n",
            "Iteration 200, Epoch 1, Loss: 1.9420149326324463, Accuracy: 31.397701263427734, Val Loss: 1.6988357305526733, Val Accuracy: 42.39999771118164\n",
            "Iteration 300, Epoch 1, Loss: 1.8559588193893433, Accuracy: 34.60859680175781, Val Loss: 1.6580696105957031, Val Accuracy: 43.29999923706055\n",
            "Iteration 400, Epoch 1, Loss: 1.7893253564834595, Accuracy: 36.99345397949219, Val Loss: 1.6093735694885254, Val Accuracy: 44.70000076293945\n",
            "Iteration 500, Epoch 1, Loss: 1.742525339126587, Accuracy: 38.541664123535156, Val Loss: 1.549770712852478, Val Accuracy: 46.20000076293945\n",
            "Iteration 600, Epoch 1, Loss: 1.7108122110366821, Accuracy: 39.72025680541992, Val Loss: 1.5107885599136353, Val Accuracy: 47.60000228881836\n",
            "Iteration 700, Epoch 1, Loss: 1.6833975315093994, Accuracy: 40.78994369506836, Val Loss: 1.4859230518341064, Val Accuracy: 49.20000076293945\n"
          ]
        }
      ],
      "source": [
        "def model_init_fn():\n",
        "    model = None\n",
        "    ############################################################################\n",
        "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    input_shape = (28,28,1) # определяем форму входных данных\n",
        "    channel_1, channel_2, num_classes = 28, 14, 10 # определяем параметры для создания модели нейронной сети\n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0) # создаем инициализатор весов с помощью VarianceScaling\n",
        "\n",
        "    # определяем слои модели нейронной сети\n",
        "    # в данном случае используются сверточные слои, слой Flatten для преобразования входных данных в плоский формат и полносвязный слой для вывода оценок классов с функцией активации softmax\n",
        "    layers = [\n",
        "        tf.keras.layers.Conv2D(channel_1, [5,5], [1,1], padding='same',\n",
        "                               kernel_initializer=initializer,\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.Conv2D(channel_2, [3,3], [1,1], padding='same',\n",
        "                               kernel_initializer=initializer,\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(num_classes,\n",
        "                              activation='softmax',\n",
        "                              kernel_initializer=initializer)\n",
        "    ]\n",
        "    model = tf.keras.Sequential(layers) # создаем последовательную модель Sequential с определенными слоями\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                            END OF YOUR CODE                              #\n",
        "    ############################################################################\n",
        "    return model\n",
        "\n",
        "learning_rate = 5e-4\n",
        "def optimizer_init_fn():\n",
        "    optimizer = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate, momentum=0.9, nesterov=True) # создаем оптимизатор стохастического градиентного спуска SGD с моментом и использованием метода Нестерова\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return optimizer\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlAd7-xAfKC2",
        "outputId": "2ad99982-b67c-4942-c1d0-d05c0f1e172b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "766/766 [==============================] - 109s 142ms/step - loss: 1.6370 - sparse_categorical_accuracy: 0.4211 - val_loss: 1.4566 - val_sparse_categorical_accuracy: 0.4740\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 1.4499 - sparse_categorical_accuracy: 0.4771\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4498828649520874, 0.4771000146865845]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model = model_init_fn()\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqJUieqJfKC3"
      },
      "source": [
        "# Использование Keras Functional API\n",
        "\n",
        "Для реализации более сложных архитектур сети с несколькими входами/выходами, повторным использованием слоев, \"остаточными\" связями (residual connections) необходимо явно указать входные и выходные тензоры.\n",
        "\n",
        "Ниже представлен пример для полносвязной сети."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYiPKgrIfKC5",
        "outputId": "dd58611c-3a69-4009-d42b-22963ae59084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ],
      "source": [
        "def two_layer_fc_functional(input_shape, hidden_size, num_classes):\n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
        "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
        "                                 kernel_initializer=initializer)(flattened_inputs)\n",
        "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                             kernel_initializer=initializer)(fc1_output)\n",
        "\n",
        "    # Instantiate the model given inputs and outputs.\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
        "    return model\n",
        "\n",
        "def test_two_layer_fc_functional():\n",
        "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
        "    input_size, hidden_size, num_classes = 50, 42, 10\n",
        "    input_shape = (50,)\n",
        "\n",
        "    x = tf.zeros((64, input_size))\n",
        "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
        "\n",
        "    with tf.device(device):\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "\n",
        "test_two_layer_fc_functional()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF43IZh-fKC5",
        "outputId": "387fe6d1-082f-4266-e3ef-5f5d9207acee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.2285590171813965, Accuracy: 7.8125, Val Loss: 3.079054117202759, Val Accuracy: 11.59999942779541\n",
            "Iteration 100, Epoch 1, Loss: 2.240535259246826, Accuracy: 28.171411514282227, Val Loss: 1.876623272895813, Val Accuracy: 39.39999771118164\n",
            "Iteration 200, Epoch 1, Loss: 2.0787038803100586, Accuracy: 32.019588470458984, Val Loss: 1.8760384321212769, Val Accuracy: 38.5\n",
            "Iteration 300, Epoch 1, Loss: 2.003521203994751, Accuracy: 34.04277420043945, Val Loss: 1.8371996879577637, Val Accuracy: 37.0\n",
            "Iteration 400, Epoch 1, Loss: 1.9341065883636475, Accuracy: 35.925811767578125, Val Loss: 1.7063727378845215, Val Accuracy: 41.5\n",
            "Iteration 500, Epoch 1, Loss: 1.8896411657333374, Accuracy: 36.907432556152344, Val Loss: 1.656093716621399, Val Accuracy: 43.599998474121094\n",
            "Iteration 600, Epoch 1, Loss: 1.8584963083267212, Accuracy: 37.85097885131836, Val Loss: 1.676419734954834, Val Accuracy: 43.0\n",
            "Iteration 700, Epoch 1, Loss: 1.8325554132461548, Accuracy: 38.51640701293945, Val Loss: 1.6361579895019531, Val Accuracy: 44.0\n"
          ]
        }
      ],
      "source": [
        "input_shape = (32, 32, 3)\n",
        "hidden_size, num_classes = 4000, 10\n",
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Iba0cgwfKC5"
      },
      "source": [
        "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут).\n",
        "\n",
        "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwR8mg6gfKC6",
        "outputId": "7bfbf4e7-f164-4dec-9634-3398fcf019f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.302915096282959, Accuracy: 12.5, Val Loss: 2.4385130405426025, Val Accuracy: 7.90000057220459\n",
            "Iteration 300, Epoch 1, Loss: 1.7545247077941895, Accuracy: 36.38911819458008, Val Loss: 1.413498044013977, Val Accuracy: 52.0\n",
            "Iteration 600, Epoch 1, Loss: 1.5641472339630127, Accuracy: 43.74480056762695, Val Loss: 1.1681092977523804, Val Accuracy: 59.60000228881836\n",
            "Iteration 900, Epoch 2, Loss: 1.180650234222412, Accuracy: 58.344905853271484, Val Loss: 1.034635066986084, Val Accuracy: 65.20000457763672\n",
            "Iteration 1200, Epoch 2, Loss: 1.1376639604568481, Accuracy: 59.93893814086914, Val Loss: 1.0103025436401367, Val Accuracy: 65.69999694824219\n",
            "Iteration 1500, Epoch 2, Loss: 1.1100674867630005, Accuracy: 60.93962860107422, Val Loss: 0.9688239097595215, Val Accuracy: 67.5999984741211\n",
            "Iteration 1800, Epoch 3, Loss: 1.0023555755615234, Accuracy: 65.22421264648438, Val Loss: 0.9039028286933899, Val Accuracy: 69.19999694824219\n",
            "Iteration 2100, Epoch 3, Loss: 0.9777933955192566, Accuracy: 65.78976440429688, Val Loss: 0.9152767658233643, Val Accuracy: 68.4000015258789\n",
            "Iteration 2400, Epoch 4, Loss: 0.8984557390213013, Accuracy: 68.4617691040039, Val Loss: 0.8714000582695007, Val Accuracy: 70.70000457763672\n",
            "Iteration 2700, Epoch 4, Loss: 0.8971531987190247, Accuracy: 68.48247528076172, Val Loss: 0.8651164770126343, Val Accuracy: 70.5999984741211\n",
            "Iteration 3000, Epoch 4, Loss: 0.8839641809463501, Accuracy: 68.9655990600586, Val Loss: 0.8141266703605652, Val Accuracy: 72.5999984741211\n",
            "Iteration 3300, Epoch 5, Loss: 0.8274450898170471, Accuracy: 70.99815368652344, Val Loss: 0.8520477414131165, Val Accuracy: 71.5999984741211\n",
            "Iteration 3600, Epoch 5, Loss: 0.8184612989425659, Accuracy: 71.43563842773438, Val Loss: 0.8137345314025879, Val Accuracy: 72.19999694824219\n",
            "Iteration 3900, Epoch 6, Loss: 0.7923651933670044, Accuracy: 72.16108703613281, Val Loss: 0.9560986161231995, Val Accuracy: 69.70000457763672\n",
            "Iteration 4200, Epoch 6, Loss: 0.7705917954444885, Accuracy: 72.64151000976562, Val Loss: 0.8364203572273254, Val Accuracy: 71.9000015258789\n",
            "Iteration 4500, Epoch 6, Loss: 0.7597911357879639, Accuracy: 73.15340423583984, Val Loss: 0.8153312802314758, Val Accuracy: 72.69999694824219\n",
            "Iteration 4800, Epoch 7, Loss: 0.7215291857719421, Accuracy: 74.03201293945312, Val Loss: 0.8102331757545471, Val Accuracy: 72.79999542236328\n",
            "Iteration 5100, Epoch 7, Loss: 0.7060989737510681, Accuracy: 74.79888916015625, Val Loss: 0.789463460445404, Val Accuracy: 73.19999694824219\n",
            "Iteration 5400, Epoch 8, Loss: 0.6634788513183594, Accuracy: 75.80128479003906, Val Loss: 0.8235307335853577, Val Accuracy: 73.29999542236328\n",
            "Iteration 5700, Epoch 8, Loss: 0.6714146137237549, Accuracy: 76.1015853881836, Val Loss: 0.8287553191184998, Val Accuracy: 73.0\n",
            "Iteration 6000, Epoch 8, Loss: 0.6566195487976074, Accuracy: 76.68231964111328, Val Loss: 0.8443731069564819, Val Accuracy: 71.9000015258789\n",
            "Iteration 6300, Epoch 9, Loss: 0.6430092453956604, Accuracy: 77.23988342285156, Val Loss: 0.8194699883460999, Val Accuracy: 73.29999542236328\n",
            "Iteration 6600, Epoch 9, Loss: 0.6332120299339294, Accuracy: 77.13729095458984, Val Loss: 0.8543833494186401, Val Accuracy: 70.9000015258789\n",
            "Iteration 6900, Epoch 10, Loss: 0.5660918951034546, Accuracy: 79.91071319580078, Val Loss: 0.8910977840423584, Val Accuracy: 71.5\n",
            "Iteration 7200, Epoch 10, Loss: 0.6067254543304443, Accuracy: 78.36421203613281, Val Loss: 0.8306968808174133, Val Accuracy: 71.69999694824219\n",
            "Iteration 7500, Epoch 10, Loss: 0.5995914340019226, Accuracy: 78.38241577148438, Val Loss: 0.8269959092140198, Val Accuracy: 73.0999984741211\n"
          ]
        }
      ],
      "source": [
        "class CustomConvNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomConvNet, self).__init__()\n",
        "        ############################################################################\n",
        "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
        "        ############################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)) # определяем сверточный слой conv1 с 16 фильтрами, размером ядра (3, 3) и функцией активации ReLU\n",
        "\n",
        "        self.conv2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu') # определяем сверточный слой conv2 с 32 фильтрами, размером ядра (3, 3) и функцией активации ReLU\n",
        "\n",
        "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2)) # определяем слой пулинга pool1 с размером окна (2, 2)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(0.25) # определяем слой dropout1 с коэффициентом отсева 0.25\n",
        "\n",
        "        self.conv3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu') # определяем сверточный слой conv3 с 64 фильтрами, размером ядра (3, 3) и функцией активации ReLU\n",
        "\n",
        "        self.flatten = tf.keras.layers.Flatten() # определяем слой flatten для преобразования данных в одномерный массив\n",
        "\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation='relu') # определяем полносвязный слой dense1 с 128 нейронами и функцией активации ReLU\n",
        "\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.4) # определяем слой dropout2 с коэффициентом отсева 0.4\n",
        "\n",
        "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax') # определяем полносвязный слой dense2 с 10 нейронами (по числу классов) и функцией активации softmax\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "        #                            END OF YOUR CODE                              #\n",
        "        ############################################################################\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        ############################################################################\n",
        "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
        "        ############################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        x = self.conv1(input_tensor) # применяем сверточный слой conv1 к входному тензору input_tensor\n",
        "        x = self.conv2(x) # применяем сверточный слой conv2 к выходу из предыдущего слоя\n",
        "        x = self.pool1(x) # применяем слой пулинга pool1 к выходу из сверточного слоя conv2\n",
        "\n",
        "        # если режим обучения равен True, то применяется слой dropout1 к выходу из слоя pool1\n",
        "        if training:\n",
        "          x = self.dropout1(x, training=training)\n",
        "\n",
        "        x = self.conv3(x) # применяем сверточный слой conv3 к выходу из слоя dropout1 или pool1, если dropout1 не был применен\n",
        "        x = self.flatten(x) # преобразовываем выход из сверточного слоя conv3 в одномерный массив\n",
        "        x = self.dense1(x) # применяем полносвязный слой dense1 к выходу из слоя flatten\n",
        "\n",
        "        # если режим обучения равен True, то применяется слой dropout2 к выходу из слоя dense1\n",
        "        if training:\n",
        "          x = self.dropout2(x, training=training)\n",
        "\n",
        "        x = self.dense2(x) # применяем полносвязный слой dense2 к выходу из слоя dropout2 или dense1, если dropout2 не был применен\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "        #                            END OF YOUR CODE                              #\n",
        "        ############################################################################\n",
        "        return x\n",
        "\n",
        "\n",
        "print_every = 300\n",
        "num_epochs = 10\n",
        "\n",
        "model = CustomConvNet()\n",
        "\n",
        "def model_init_fn():\n",
        "    return CustomConvNet()\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    learning_rate = 1e-3\n",
        "    return tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKpce8oVfKC6"
      },
      "source": [
        "Опишите все эксперименты, результаты. Сделайте выводы."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Архитектура сети состоит из: сверточных слоев, максимального пулинга, dropout, flatten и полносвязных слоев.\n",
        "\n",
        "На одинаковых настройках были протестированы различные оптимизаторы: SGD, Adam, RMSprop. Первый показал наихудшие результаты - за 10 эпох точность была в районе 33%. Последние два показали примерно одинаковые результаты, но в большинстве своем Adam был на несколько сотых точнее.\n",
        "\n",
        "На входном и скрытом слоях сравнивались функции активации relu и sigmoid, а на входном слое тестировались sigmoid и softmax. При комбинации sigmoid, softmax и Adam был получен наихудший результат - для получения необходимой точности нужно было примерно 15 эпох. При комбинации relu, softmax и Adam был получен наилучший результат - 73% accuracy на валидационной выборке за 10 эпох обучения."
      ],
      "metadata": {
        "id": "XDJC6zPzGfNw"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}